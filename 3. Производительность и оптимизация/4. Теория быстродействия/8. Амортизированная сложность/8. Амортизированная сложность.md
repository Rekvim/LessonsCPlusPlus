## Амортизированная сложность
Вы уже встречали словосочетание «амортизированная константа» в начале темы. Тогда амортизированной $O(1)$ была названа операция вставки в конец вектора. Далее в курсе вы узнаете, как она устроена и почему $O(1)$ в этом случае амортизирована. А пока рассмотрим совершенно другой пример. 

Одно из прошлых заданий состояло в том, чтобы использовать два стека для реализации очереди. Реализация могла быть такой:

```cpp
#include <cassert>
#include <stack>

using namespace std;

// моделируем очередь с помощью двух стеков
template <class T>
class QueueFromStack {
public:
    void Push(const T& e) {
        stack1_.push(e);
    }

    T Pop() {
        if (stack2_.empty()) {
            while (!stack1_.empty()) {
                stack2_.push(stack1_.top());
                stack1_.pop();
            }
        }

        assert(!stack2_.empty());

        T top = stack2_.top();
        stack2_.pop();
        return top;
    }
OnTrainArrive
private:
    stack<T> stack1_;
    stack<T> stack2_;
};

int main() {
    QueueFromStack<int> q;
    q.Push(1);
    q.Push(2);
    q.Push(3);
    q.Push(4);
    assert(q.Pop() == 1);
    assert(q.Pop() == 2);
    assert(q.Pop() == 3);
    assert(q.Pop() == 4);
} 
```
Новые элементы кладём в первый стек, а когда нужно вынуть, перекладываем все элементы из первого во второй.

У такого алгоритма может быть и практическое применение. Представьте, что на склад приехала машина с большими плоскими пронумерованными коробками. Её разгружают, складывая коробки друг на друга. За коробками приходят клиенты, и отдавать надо по порядковому номеру: то есть первой — нижнюю коробку. Тогда рабочие должны переложить все коробки в другую стопку и отдавать из неё.

Подумаем, будет ли эта реализация очереди эффективной хотя бы с точки зрения сложности. Сомнения вызывает то, что в константной для стека операции `Pop` есть целый цикл. Пусть задача формулируется так: в очередь положили N элементов и сделали в общей сложности N операций `Pop`. При этом `Push` и `Pop` могли идти в любом порядке. Нужно оценить асимптотическую сложность этого алгоритма. Как и раньше, будем оценивать именно худшую сложность. Операция `Push` выглядит просто: она делает одну вставку, выполняющуюся за время $O(1)$. 

Худший случай — это когда положили сразу много — примерно $N$ — элементов, а только потом сделали `Pop`. Тогда цикл также должен будет сделать порядка $N$ операций переброски элемента из одного стека в другой. Получается, время работы `Pop` хуже, чем для обычной очереди, а именно $O(N)$.

Поскольку всего сделано N операций `Pop`, сложность всей программы не обрадует: $O(N^2)$.

Взглянем на ситуацию с точки зрения судьбы каждого элемента. В начале элемент попадает в первый стек, затем извлекается из него и попадает во второй. И только потом извлекается окончательно. Непростая судьба, но всё равно константная. Такой подсчёт показывает, что нужно только по две операции `push` и `pop` на каждый элемент. Итоговая сложность получится уже $O(N)$, а не $O(N^2)$, как было вначале.

Похоже, мы слишком увлеклись худшими случаями, и оценка сложности получилась чересчур грубой. А именно оценка сложности цикла в операции `Pop`. Несмотря на то, что в худшем случае этот цикл действительно делает $N$ операций, суммарное количество его итераций составит не более $N$ на все вызовы `Pop`.

Если усредним $N$, увидим, что в среднем вызов Pop работает за $O(1)$. Это и есть амортизированная сложность. С точки зрения итогового времени работы программы разницы между $O(1)$ и амортизированной $O(1)$ нет. Но у такой сложности есть особенности. Может случиться, что функция много раз подряд работает быстро, и вдруг происходит плохой случай. Функция подвисает, обрабатывая элементы, которые накопились за всё время.

Иными словами, время работы неравномерно. Такое поведение амортизированной константы иногда нежелательно. Например, когда вы программируете компьютерную игру, которая должна моментально реагировать на действия пользователя. Если реакция почти всё время моментальная или даже быстрее, чем нужно, и вдруг игра подвисает, пользователь вряд ли будет доволен. Равномерность скорости критична и для звуковых приложений. При воспроизведении аудио подвисание будет звучать как громкий и неприятный «пш».

Другой пример:

```cpp
#include <iostream>
#include <string>
#include <deque>

using namespace std;

class TrainTerminal {
public:
    void OnPassengerArrive(const string& name) {
        passengers_on_platform_.push_back(name);
    }

    void OnTrainArrive() {
        cout << "Список пассажиров поезда:"s << endl;
        int id = 1;
        while (!passengers_on_platform_.empty()) {
            cout << (id++) << passengers_on_platform_.front() << endl;
            passengers_on_platform_.pop_front();
        }
    }

    bool FindPassenger(const string& name) const {
        auto iter = find(passengers_on_platform_.begin(), passengers_on_platform_.end(), name);
        return iter != passengers_on_platform_.end();
    }

private:
    deque<std::string> passengers_on_platform_;
}; 
```
Этот класс реализует железнодорожную платформу, на которую прибывают электрички и приходят пассажиры. Считается, что есть только один маршрут, поэтому поезд забирает всех пассажиров, которые в данный момент находятся на платформе. По прибытии поезда программа печатает список всех его пассажиров. Обозначим количество пассажиров через $N$. Количество поездов в этот день составляет $\dfrac{N}{100}$. Служба безопасности $3N$ раз искала подозрительных пассажиров, применяя `FindPassenger`. 

Действительно, в неудачном для пассажиров случае метод `OnTrainArrive` отправит их всех или почти всех в одном поезде, заставляя проклинать ненавистный час пик и транспортную компанию. Поэтому худшая сложность метода составит целых $O(N)$. Но каждый пассажир будет отправлен лишь однажды, поэтому суммарное количество витков цикла внутри `OnTrainArrive` никогда не превысит $N$. Раз $\dfrac{N}{100}$ вызовов метода заставили его обработать всего $N$ пассажиров, значит, в среднем один вызов обрабатывал 100 пассажиров, что тоже вписывается в обозначение $O(1)$.

Это ещё один замечательный пример амортизированной сложности: каждый вызов функции может обработать много элементов, но все вызовы в совокупности обработают не больше общего количества элементов.

Не путайте амортизированную сложность со средней. Некоторые алгоритмы могут работать быстро или медленно в зависимости от входных данных. Например, сортировка. Обычно она работает за $O(NlogN)$, но если вектор отсортирован изначально, сортировка может определить это за $O(N)$ и завершиться. В этом лучшем случае её сложность будет $O(N)$. Средней сложностью называют усреднение сложности по всем возможным входным данным. Это вовсе не гарантирует быструю работу в каждом случае. Например, злоумышленники могут специально подобрать данные, чтобы «повесить» алгоритм, даже если он имеет хорошую среднюю сложность.

В то же время амортизированная сложность гарантирует быструю работу — вернее, быструю работу программы в итоге, после выполнения многих подобных операций. Амортизированная сложность не гарантирует, что каждый вызов функции или метода будет быстрым. Но если таких вызовов сделать много, плохих случаев окажется мало, и в совокупности количество операций будет всё равно небольшим.