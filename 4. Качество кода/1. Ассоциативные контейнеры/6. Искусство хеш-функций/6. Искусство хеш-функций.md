## Искусство хеш-функций
Как вы увидели в прошлом уроке, неупорядоченный контейнер сильно зависит от хеш-функции. Если хешер плохой, то контейнер будет работать неэффективно — даже хуже, чем его «коллега» set или map. И у хеш-функции есть минимум две причины быть плохой:
- она может учитывать не все данные объекта, провоцируя коллизии,

- она может медленно вычисляться.
  
Решая задачу, вы научились строить совершенную хеш-функцию, значения которой никогда не совпадают для разных объектов. Подумаем, всегда ли это возможно. Попробуем захешировать структуру, задающую фрагмент файла позициями начала и конца фрагмента:

```cpp
#include <cstdint>

struct Fragment {
    uint64_t begin;
    uint64_t end;
}; 
```

Поля структуры имеют размер 64 бита, а значит, могут принимать $2^{64}$ различных значений. Вся структура содержит два таких поля, а значит, может иметь $2^{128}$ различных значений. Результат хеш-функции представлен числом типа `size_t`, занимающим обычно 64 бита. Чтобы посчитать количество всевозможных хешей, возведём двойку в степень 64. Получим, что количество различных хешей гораздо меньше, чем количество различных значений структуры `Fragment`. Это значит, что как бы мы не реализовывали хеш-функцию, всегда будут возможны коллизии — различные объекты `Fragment`, имеющие одинаковые хеши. Подобное относится и к хешированию `string`, которое мы неявно использовали, когда применяли `unordered_set` для подсчёта частот слов в произведении Чосера.

Хеширование ещё называют необратимым шифрованием. Шифрованием — потому что оно кодирует данные. Необратимым — потому что восстанавливать по коду исходные данные не нужно и, скорее всего, невозможно. Представьте, что регистрируетесь на каком-либо интернет-ресурсе. Если он сделан профессионально, он не будет сохранять ваш пароль. Пароль должен немедленно уничтожаться, сводя возможность утечки на нет. Профессионально сделанный сайт запомнит только некоторый хеш вашего пароля. Этого достаточно для проверки его правильности, но недостаточно для восстановления. Отсюда следует, что непременно существуют другие пароли, по которым можно войти в систему наравне с вашим. Количество хешей меньше, чем количество паролей. Разные пароли неизбежно имеют одинаковые хеши.

Поскольку реализовать совершенный хешер для `Fragment` невозможно, реализуем несовершенный:
```cpp
struct FragmentHasher {
    size_t operator() (const Fragment& f) const {
        return static_cast<size_t>(f.begin + f.end);
    }
}; 
```
Как вы думаете, в каком из следующих случаев возникнет коллизия двух фрагментов? — Когда каждый фрагмент имеет одинаковый отступ от начала и конца файла

Как видим, коллизии могут возникать во вполне естественных случаях. Изменим эту функцию, чтобы её вычисление оставалось быстрым, но коллизии были менее вероятны:
```cpp
struct FragmentHasher {
    static const uint64_t N;
    size_t operator() (const Fragment& f) const {
        return static_cast<size_t>(f.begin * N + f.end);
    }
}; 
```

По некоторым статистическим соображениям обычно в качестве N выбирают простое число, например 37. Для обычных целей будет вполне достаточно такой хеш-функции, но её минус в том, что есть простой алгоритм, позволяющий находить коллизии:
```cpp
int main() {
    FragmentHasher hasher;
    Fragment f1{10, 1000};
    Fragment f2{10 + 1, 1000 - 37 * 1};
    Fragment f3{10 + 2, 1000 - 37 * 2};
    Fragment f4{10 + 3, 1000 - 37 * 3};

    cout << "f1 hash - "s << hasher(f1) << endl;
    cout << "f2 hash - "s << hasher(f2) << endl;
    cout << "f3 hash - "s << hasher(f3) << endl;
    cout << "f4 hash - "s << hasher(f4) << endl;
} 
```
Результат программы:
```
f1 hash - 1370
f2 hash - 1370
f3 hash - 1370
f4 hash - 1370 
```
Более совершенные хеш-функции, используемые в криптографии, имеют собственные названия: MD5, SHA-512, BLAKE3. Алгоритм поиска коллизий для них крайне сложный и требует больших вычислительных ресурсов. Маловероятно, что коллизии будут возникать естественным образом или будут подобраны злоумышленниками.

Функция MD5 не считается криптографически стойкой, и алгоритм поиска коллизий известен. Чтобы усложнить их поиск, добавляют соль — некоторую фиксированную секретную строку, которую приписывают к данным до хеширования.

Криптографические хеш-функции вычисляются достаточно медленно. В криптографических задачах это иногда даже считается плюсом, но на практике их лучше не использовать без необходимости. Как правило, бывает достаточно хеш-функции из приведённого примера с умножением на простое число. Рассмотрим структуру, состоящую из трёх полей и задающую окружность на плоскости:
```cpp
struct Circle {
    double x;
    double y;
    double r;
}; 
```
Можно вычислить хеш каждого из трёх полей структуры, используя хешер `std::hash<double>`, а затем объединить их, умножив на число $37$. Одну компоненту нужно умножать на $37$, а вторую на $37^2$:
```cpp
struct CircleHasher {
    size_t operator() (const Circle& circle) const {
        size_t h_x = d_hasher_(circle.x);
        size_t h_y = d_hasher_(circle.y);
        size_t h_r = d_hasher_(circle.r);
        
        return h_x + h_y * 37 + h_r * (37 * 37);
    }

private:
    std::hash<double> d_hasher_;
}; 
```

Такая хеш-функция будет обладать хорошими статистическими свойствами, обеспечивая равномерное заполнение корзинок. Если полей больше, можно складывать их хеши, умножая на новые степени числа $37$: на $37^3$, $37^4$, $37^5$ и т. д. Только учтите — разные параметры хешируемых данных должны обязательно умножаться на разные степени простого числа. Если степень у двух параметров получится одинаковой, статистические свойства хеш-функции ухудшатся.

Выхода за пределы допустимого диапазона `size_t` при этом можно не бояться — на качестве хеш-функции это не отразится. Так можно хешировать произвольные типы данных, объединяя поля, которые могут иметь самые разные типы. Даже не обязательно, чтобы их количество было заранее известно. Приведём пример — реализуем хешер для `vector<int>`:

```cpp
struct IntVectorHasher {
    size_t operator() (const vector<int>& vec) const {
        size_t res = 0;
        for (int num : vec) {
            res = res * 37 + static_cast<size_t>(num);
        }
        return res;
    }
}; 
```

Хеш-функция перемешивает данные, делая их неузнаваемыми. И если для обычной функции понятность и предсказуемость результата — это плюс, то для хеш-функции — большой минус. Она должна запутать данные как можно сильнее. Если при этом происходит что-нибудь необратимое и непонятное, прекрасно — значит, коллизии будут возникать реже. Однако в практических примерах, не связанных с криптографией, на первом месте остаётся производительность.

Это был последний урок о хеш-функциях. Чтобы проверить, насколько хорошо вы усвоили эту непростую тему, пройдите тест.